{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm-2.2.5/en_core_web_sm/en_core_web_sm-2.2.5\")\n",
    "nlp = spacy.load(\"en_core_web_md-3.0.0/en_core_web_md-3.0.0/en_core_web_md/en_core_web_md-3.0.0\")\n",
    "\n",
    "# import sentiment analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from absapi_sentiment_extractor import *\n",
    "# from absapi_aspect_class_prediction_engine import *\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absapi sentiment extractor loaded......\n"
     ]
    }
   ],
   "source": [
    "# pred_engine()\n",
    "sent_extract_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"ChromeRevs5000.csv\",header=None)\n",
    "df.columns=[\"Rev_no\",\"reviews\"]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "# df=df.drop(\"no\",axis=1)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "dfs.append(df)\n",
    "df_review = pd.concat(dfs[:4])\n",
    "len(df_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_no</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2648</td>\n",
       "      <td>i love it but the operating system could use s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2456</td>\n",
       "      <td>I bought the chromebook thinking that I will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4557</td>\n",
       "      <td>I have never posted a review on Amazon, but I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4884</td>\n",
       "      <td>I've been a Google Chrome user since the day t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>I bought this laptop a few weeks ago and I was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_no                                            reviews\n",
       "0    2648  i love it but the operating system could use s...\n",
       "1    2456  I bought the chromebook thinking that I will b...\n",
       "2    4557  I have never posted a review on Amazon, but I ...\n",
       "3    4884  I've been a Google Chrome user since the day t...\n",
       "4      92  I bought this laptop a few weeks ago and I was..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review.to_csv(\"df_chrome_reviews.csv\")\n",
    "#Later we will read this file to create the 5000 reviews with unique IDs=rev_no: and text as reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv(\"df_chrome_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_no</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2648</td>\n",
       "      <td>i love it but the operating system could use s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2456</td>\n",
       "      <td>i bought the chromebook thinking that i will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4557</td>\n",
       "      <td>i have never posted a review on amazon, but i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4884</td>\n",
       "      <td>i've been a google chrome user since the day t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>i bought this laptop a few weeks ago and i was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_no                                            reviews\n",
       "0    2648  i love it but the operating system could use s...\n",
       "1    2456  i bought the chromebook thinking that i will b...\n",
       "2    4557  i have never posted a review on amazon, but i ...\n",
       "3    4884  i've been a google chrome user since the day t...\n",
       "4      92  i bought this laptop a few weeks ago and i was..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews=df_reviews.drop(\"Unnamed: 0\",axis=1)\n",
    "df_reviews[\"reviews\"] = df_reviews[\"reviews\"].str.lower()\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lbs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-66ffd287f0c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maspect_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# aspect_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lbs' is not defined"
     ]
    }
   ],
   "source": [
    "aspect_classes = lbs\n",
    "# aspect_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "time:  612.5911829471588\n",
      "DONE!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from csv import writer\n",
    "t0 = time.time()\n",
    "sentno=0\n",
    "df_with_aspects = pd.DataFrame()\n",
    "df_without_aspects = pd.DataFrame()\n",
    "\n",
    "for row in range(len(df_reviews[\"rev_no\"])):\n",
    "    rev_id = df_reviews[\"rev_no\"][row]\n",
    "    rev_number = row+1\n",
    "    \n",
    "    if rev_number % 100==0:\n",
    "        print(rev_number)\n",
    "    \n",
    "    \n",
    "    rev = df_reviews.reviews[row]\n",
    "\n",
    "\n",
    "    #     print (aspect_keywords)\n",
    "#     for rev in df_reviews.reviews:\n",
    "\n",
    "    review_lines = nltk.sent_tokenize(rev)\n",
    "    for sentence in review_lines:\n",
    "        matches =[]\n",
    "        poloarity =\"--\"\n",
    "\n",
    "#             sentence_words = nltk.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "\n",
    "        for aspect_class in aspect_classes:\n",
    "            aspect_keywords=eval(aspect_class)\n",
    "#                 found = intersection(aspect_keywords, sentence_words) # no duplicate management\n",
    "            for word in aspect_keywords:\n",
    "                if sentence.find(word) !=-1:\n",
    "                    matches.append([word,aspect_class])\n",
    "\n",
    "#                 if len(found)>0: #no empty found managed for now.\n",
    "#                     print(found[0])\n",
    "#                     for f in found:\n",
    "#                         print(f)\n",
    "#                         matches.append(f)\n",
    "#                 details=[]\n",
    "        if len(matches)>0:\n",
    "            sentno=sentno+1       \n",
    "\n",
    "#                 print(matches)\n",
    "            for match in matches:\n",
    "                keyword=match[0]\n",
    "                aspect_class = match[1]\n",
    "                compiled_sentiment,tree=compile_ensemble_sentiment(sentence,keyword,nlp, analyzer)\n",
    "                polarity = compiled_sentiment['compound']\n",
    "\n",
    "                graph_data= [rev_id,sentno,sentence,keyword, polarity,aspect_class]\n",
    "                \n",
    "                \n",
    "                with open(\"gbcfa_graphdata_with_aspects_clean.csv\", 'a+', newline='',encoding='utf-8') as write_obj:\n",
    "                    # Create a writer object from csv module\n",
    "                    csv_writer = writer(write_obj)\n",
    "                    # Add contents of list as last row in the csv file\n",
    "                    csv_writer.writerow(graph_data)\n",
    "\n",
    "                \n",
    "                \n",
    "#                     print(graph_data)\n",
    "#                 df_with_aspects.append(pd.Series(graph_data,index=[\"rev_id\",\"sentno\",\"sentence\",\"match\", \"polarity\",\"aspect_class\"]),ignore_index=True)\n",
    "#                     print(\" \")\n",
    "        else:\n",
    "            sentno=sentno+1\n",
    "            polarity =\"--\"\n",
    "            aspect_class = \"--\"\n",
    "            match = \"--\"\n",
    "            graph_data= [rev_id,sentno,sentence,match, polarity,aspect_class]\n",
    "\n",
    "            with open(\"gbcfa_graphdata_without_aspects_clean.csv\", 'a+', newline='', encoding='utf-8') as write_obj:\n",
    "                # Create a writer object from csv module\n",
    "                csv_writer = writer(write_obj)\n",
    "                # Add contents of list as last row in the csv file\n",
    "                csv_writer.writerow(graph_data)\n",
    "            \n",
    "            \n",
    "            \n",
    "#                 print(graph_data)\n",
    "#             df_without_aspects.append(pd.Series(graph_data,index=[\"rev_id\",\"sentno\",\"sentence\",\"match\", \"polarity\",\"aspect_class\"]),ignore_index=True)\n",
    "#                     details = [rev,matches]\n",
    "#                     graph_data.append(details)\n",
    "#                     print (matches)\n",
    "#                     print(sentence)\n",
    "# df_with_aspects.to_csv(\"absapi_graphdata_with_aspects.csv\")\n",
    "# df_without_aspect.to_csv(\"absapi_graphdata_without_aspects.csv\")\n",
    "t1= time.time()\n",
    "print(\"time: \", t1-t0)\n",
    "print(\"DONE!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5000\n",
    "# time:  1362.564370393753\n",
    "# DONE!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"the operating system could use some instructions\"\n",
    "aspect= \"the operating system\"\n",
    "\n",
    "compiled_sentiment,tree=compile_ensemble_sentiment(sentence,aspect,nlp, analyzer)\n",
    "compiled_sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1589"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"the operating system is a terrible piece of software\"\n",
    "aspect= \"the operating system\"\n",
    "\n",
    "compiled_sentiment,tree=compile_ensemble_sentiment(sentence,aspect,nlp, analyzer)\n",
    "compiled_sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4766999999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"the operating system is a terrible piece of software\"\n",
    "aspect= \"software\"\n",
    "\n",
    "compiled_sentiment,tree=compile_ensemble_sentiment(sentence,aspect,nlp, analyzer)\n",
    "compiled_sentiment['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"gbcfa_graphdata_with_aspects_clean.csv\")\n",
    "df.to_csv(\"gbcfa_graphdata_with_aspects_clean.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"gbcfa_graphdata_without_aspects_clean.csv\")\n",
    "df.to_csv(\"gbcfa_graphdata_without_aspects_clean.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
